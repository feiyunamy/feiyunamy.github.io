---
title: 理解自然语言处理中的CNN
updated: 2018-12-19 21:08
---
本文翻译自[Denny Britz](http://www.wildml.com/about/)的博客[《Understanding Convolutional Neural Networks for NLP》](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)，文章对于CNN在NLP领域中的应用讲述深入浅出，引用的很多资料也非常有用。  
***
每当我们听到卷积神经网络（CNNs），我们最先想到的应该就是计算机视觉。CNNs的应用是图片分类任务取得巨大突破的主要原因，也是目前大多数计算机视觉系统的核心，比如Facebook的照片自动标记以及自动驾驶等领域。

最近以来，CNNs也被应用到许多自然语言处理方面的问题上，并且已经取得了一些很有趣的成果。在这篇博文中，我将尝试概述CNNs到底是什么，以及它在NLP中是如何使用的。CNNs在计算机视觉领域的应用从直觉上来说更加容易理解，所以我也将从计算机视觉开始讲起，并逐渐延伸到自然语言处理中。
## 卷积是什么？
对我来说最简单的理解卷积的方式是把它想象成作用在一个矩阵上的滑动窗口函数。虽然这样很口语化，但是这种方式很容易清楚的理解它，请看下面的可视化例子：
![](http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif)
*大小为3x3的卷积核进行的卷积操作，[图片来源](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)*  

可以把左边的矩阵想象为一张黑白图片。矩阵中的每个数字对应一个像素，0代表黑色，1代表白色（在灰度图中，像素的值一般是在0~255之间）。滑动的窗口就叫做卷积核、过滤器或者特征检测器。这里我们用了一个3x3大小的过滤器，把它的值与原始矩阵中的值对应相乘，再求和。为了完成完整的卷积操作，我们通过滑动窗口来对矩阵中的每个元素都做上述操作。

你可能想知道，通过上述的卷积操作，到底做了什么？下面是一些直观的例子：

**通过求每个像素与其邻近像素的平均值来对图片进行模糊化处理：**

![](http://docs.gimp.org/en/images/filters/examples/convolution-blur.png)![image](http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-blur.jpg)

**通过求每个像素与其邻近像素之间的差值来检测边缘：**

![](http://docs.gimp.org/en/images/filters/examples/convolution-edge-detect1.png)![](http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-edge-detect.jpg)

[这里GIMP manual](http://docs.gimp.org/en/plug-in-convmatrix.html)还有一些例子。为了对CNN的工作机制有更加深入的理解，我推荐阅读[这篇博客](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)

## 卷积神经网络是什么？

现在你已经懂了卷积是什么。但是，卷积神经网络是什么呢？CNNs基本上就是若干层卷积再加上作用在结果上的[ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))或者[tanh](https://reference.wolfram.com/language/ref/Tanh.html)等非线性激活函数。在传统的前馈神经网络中，我们将输入层的神经元与下一层输出层的神经元挨个连接起来，这样的神经网络也被称为一个全连接层，或者仿射层。在CNN中，我们并不这么做。取而代之的，我们用卷积遍历输入层来获得输出值。这样的操作就是局部链接，即输入的每个区域连接到输出层中的神经元。每一层用不同的卷积核，通常是成百上千个上面提到的卷积操作，并把它们的结果结合起来。另外还有个东西叫做池化层（subsampling），这个后面会讲到。在训练阶段，CNN可以根据具体任务的不同来自动的学习卷积核的值。例如，在图片分类任务中，CNN的第一层可能会学习如何识别边缘，然后利用第一层识别到的边缘特征在第二层中识别简单的形状，然后利用这些简单的形状来探测更加高级的特征，比如说在更高的层中试着探测面部形状。最后一层是一个可以利用前面提取到的特征的分类器。
![CNN in CV](http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png)
## 这些如何应用于NLP呢？
不同于图片像素，大部分NLP任务的输入是有句子或者文档的矩阵表示。矩阵的每一行对应于一个token，通常是一个单词，但也可以是一个字母。也就是说，每一行是一个单词的向量表示。通常情况，这些向量就是词嵌入（word embeddings）(低维度表示)，例如[word2vec](https://code.google.com/p/word2vec/)或者[GloVe](http://nlp.stanford.edu/projects/glove/)，但是它们也可以是one-hot向量，将所有的词索引为一个词汇表。例如一个有10个单词的句子，用100维的word embedding，我们就会得到一个10x100的矩阵作为我们的输入。这就是我们的“图像”。

在视觉领域，卷积核依次滑过图片的每一块，但是在NLP中卷积核一般是滑动经过矩阵的整个一行（一些单词），因此，卷积核的宽度通常情况下与输入矩阵的宽度相等。卷积核的高度，或者说区域大小，是可以随意取值的，但是滑动经过2-5个单词的窗口大小是最常使用的。综上所述，一个适用于NLP的卷积神经网络看起来长这个样子（花几分钟时间来理解下面这幅图片，关注一下向量的维度是如何计算的。你可以先不用管池化操作，我们后面会讲到）：

![CNN in NLP](http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM.png)  
*用于文本分类的CNN的结构图如上所示。这里我们画出了三个不同大小的卷积核：2，3，4，每个大小都有两个卷积核。每个卷积核对句子的矩阵表示进行卷积操作，生成不同大小的特征图（feature map）。然后对每个特征图进行最大池化操作（max pooling）,即，只把每个特征图中最大的那个数记录下来。这样的话通过组合6个特征图的池化结果，我们可以得到一个特征向量（通过倒数第二层来结合它们）。最后一层的softmax接收这个特征向量作为输入，据此来对句子进行分类，这里我们假设是一个二分类问题，因此只画出了两个输出结果。
图片来源：Zhang, Y., & Wallace, B. (2015). A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification.*  
---
### 对于上述维度变化的解释：(翻译时增加内容)  
<font color = "red">首先，输入矩阵的大小为7x5，对于大小为4的卷积核，即覆盖区域为4个单词，卷积核矩阵的维度为4x5，每次卷积操作可以得到特征图中的一个值（对应相乘相加），昨晚第一次卷积操作后，大小为4的卷积核开始滑动，滑动步长默认为1。经过4次滑动可以覆盖整个输入矩阵，所以输出的特征图的维度为4x1。后面对应大小的滑动操作以此类推。特别的，对于输入长度为n，卷积核大小为m的卷积操作，最终输出的特征图大小（滑动次数）为：n - m + 1。</font>  
  
那么，在计算机视觉领域我们那种良好的直觉感受，现在还适用吗？位置不变性和局部构图性对图像具有直观意义，但对于NLP而言并非如此。你可能会非常关心句子中某一个词出现的位置。位置上相邻的像素点在语义上通常也是有联系的（共同组成图像中某个物体的一部分），但是对于单词来说这是不一定的。在很多种语言中，一个短语的各部分可能会被很多的其他单词分隔开。在组成成分方面，单词表现得也不是那么明显。可以确定的是，单词确实有固定的搭配方式，比如形容词通常用于修饰名词，但是这样的搭配多大程度上是正确的，或者说卷积操作提取物出的更高级别的表示到底是什么意思，表现得并不像在计算机视觉中那么的明显。