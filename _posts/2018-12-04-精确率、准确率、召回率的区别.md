---
title: 精确率、准确率与召回率之间的区别
updated: 2018-12-04 16:17
---
这几个概念遇到过很多次，但是每次都搞得很乱，不是很清楚，就算有混淆矩阵也是很乱，而且对于准确率与召回率引入的必要性一直不是很懂（当时感觉就是引入来搞我们的），偶然间看到西瓜书上面的解释，顿时茅塞顿开，下面分析一下它们之间的区别。
西瓜书原文如下：

`错误率和精度虽然常用，但并不能满足所有任务的需求。以西瓜问题为例，假定瓜农拉来一车西瓜，我们用训练好的模型对这些西瓜进行判别，显然，错误率衡量了有多少比例的西瓜被判别错误，但是我们关心的是，“挑出的西瓜中有多少比例是好瓜”，或者“所有好瓜中有多少比例被挑出来了”，那么错误率就显然不够用了，这是需要使用其他的性能度量。`

`或者还有一个例子，在Web检索应用中，“检索出的内容有多少比例是用户感兴趣的”（查准率），“用户感兴趣的比例有多少被检索出来了”（查全率）`

## 准确率（Accuracy）
首先是精确率，准确率主要是一个整体的衡量，又称为精度，讨论这个概念之前先来看另一个概念，错误率，假设总共的样本数量为w，预测错误的数量为a，则错误率为：a / w * 100%。

因此，准确率可以表示为：1 - 错误率。

## 精确率（查准率 Precision）

先上结果混淆矩阵。

|  真实情况 | 预测结果 | 预测结果 |
| :------: | :------: | :------: |
|  |   正例   |   反例   |
|   正例   |    TP    |    FN    |
|   反例   |    FP    |    TN    |

精确率又称为查准率，直观的理解是“找出来的模型认为是正确的样本中，有多少是真正正确的”。即模型认为的正确的数量为：TP + FP（无论真实情况是什么，模型均认为它是正例），而在这些样本中，真正正确的数量为：TP。所以，精确率定义为：

$$
Precision=\frac{TP}{TP+FP}
$$

举一个具体的栗子，模型认为有 TP+FP 个好瓜，但是模型是有问题的，其实在模型认为的好瓜中，真正的好瓜只有TP个。

## 召回率（查全率 Recall）

同上的例子。

召回率又称为查全率，比较直观的理解为，“所有的正确的例子中，有多大的比例被模型预测对了”，即所有正确的样本数量为：TP + FN ， 模型识别出来并且正确的正例数量为： TP。所以，召回率定义为：

$$
Recall=\frac{TP}{TP+FN}
$$

同上的瓜的例子，总共实际有的好瓜的数量为：TP+FN，其中被模型正确识别出来的好瓜数量为：TP。

综上，感觉真正理解这几个参数的关键在于在真实使用的过程之中，一定要能确定出分母位置上的具体值应该是多少。

同样的，最上面提到的准确率可以定义为：

$$
Accuracy = 1-\frac{FP+FN}{TP+TN+FP+FN}=\frac{TP+TN}{TP+TN+FP+FN}
$$